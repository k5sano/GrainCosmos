#include "PluginProcessor.h"
#include "PluginEditor.h"

//==============================================================================
GrainCosmosAudioProcessor::GrainCosmosAudioProcessor()
    : AudioProcessor(BusesProperties()
                        .withInput("Input", juce::AudioChannelSet::stereo(), true)
                        .withOutput("Output", juce::AudioChannelSet::stereo(), true))
    , parameters(*this, nullptr, "Parameters", createParameterLayout())
{
}

GrainCosmosAudioProcessor::~GrainCosmosAudioProcessor()
{
}

//==============================================================================
void GrainCosmosAudioProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    currentSampleRate = sampleRate;

    // Setup DSP spec for stereo
    spec.sampleRate = sampleRate;
    spec.maximumBlockSize = static_cast<juce::uint32>(samplesPerBlock);
    spec.numChannels = 2;  // Stereo input/output

    // Prepare the delay buffer for maximum delay time
    int maxDelaySamples = static_cast<int>(sampleRate * maxDelaySeconds);
    grainBuffer.setMaximumDelayInSamples(maxDelaySamples);
    grainBuffer.prepare(spec);

    // Reset freeze state on prepare
    freezeEnabled.store(false, std::memory_order_relaxed);
    inputGainRamp = 1.0f;
    samplesSinceUnfreeze = 0;

    // Reset grain scheduler
    samplesSinceLastGrain = 0;
    nextGrainInterval = 1;

    // Clear all grain voices
    for (auto& voice : grainVoices)
    {
        voice.active = false;
        voice.readPosition = 0.0f;
        voice.windowPosition = 0.0f;
        voice.playbackRate = 1.0f;
        voice.pan = 0.5f;
        voice.grainLengthSamples = 0;
        voice.pitchSemitones = 0;
        voice.reversed = false;
        voice.attackPhase = 0.0f;
        voice.decayPhase = 1.0f;
    }

    // Reset feedback
    feedbackSampleL = 0.0f;
    feedbackSampleR = 0.0f;
}

//==============================================================================
void GrainCosmosAudioProcessor::releaseResources()
{
    // Optional: Release large buffers to save memory when plugin not in use
    wetBuffer.setSize(0, 0);
    dryBuffer.setSize(0, 0);
}

void GrainCosmosAudioProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages)
{
    juce::ScopedNoDenormals noDenormals;
    juce::ignoreUnused(midiMessages);

    const int numSamples = buffer.getNumSamples();

    // Ensure buffers are large enough (in case host uses different block size)
    if (wetBuffer.getNumSamples() < numSamples)
    {
        wetBuffer.setSize(2, numSamples, false, false, true);
        dryBuffer.setSize(2, numSamples, false, false, true);
    }

    // Read parameters atomically (real-time safe)
    auto* delayTimeParam = parameters.getRawParameterValue("delay_time");
    auto* mixParam = parameters.getRawParameterValue("mix");
    auto* feedbackParam = parameters.getRawParameterValue("feedback");
    auto* feedbackSatParam = parameters.getRawParameterValue("feedback_saturation");
    auto* grainDensityParam = parameters.getRawParameterValue("grain_density");
    auto* pitchRangeParam = parameters.getRawParameterValue("pitch_range");
    auto* bufferPosParam = parameters.getRawParameterValue("buffer_position");
    auto* characterParam = parameters.getRawParameterValue("character");
    auto* chaosParam = parameters.getRawParameterValue("chaos");
    auto* grainSizeParam = parameters.getRawParameterValue("grain_size");
    auto* envelopeShapeParam = parameters.getRawParameterValue("envelope_shape");
    auto* distortionParam = parameters.getRawParameterValue("distortion_amount");
    auto* freezeParam = parameters.getRawParameterValue("freeze");
    auto* tempoSyncParam = parameters.getRawParameterValue("tempo_sync");

    float delayTimeSec = delayTimeParam->load();
    float mixValue = mixParam->load() / 100.0f;
    float feedbackGain = feedbackParam->load() / 100.0f;
    float feedbackSaturation = feedbackSatParam->load();
    float grainDensity = grainDensityParam->load();
    float pitchRange = pitchRangeParam->load() / 100.0f;
    float bufferPosition = bufferPosParam->load() / 100.0f;
    float characterAmount = characterParam->load() / 100.0f;
    float chaosAmount = chaosParam->load() / 100.0f;
    float grainSizeMs = grainSizeParam->load();
    float envelopeShape = envelopeShapeParam->load();
    float distortionAmount = distortionParam->load();
    bool freezeRequested = freezeParam->load() > 0.5f;
    bool tempoSyncEnabled = tempoSyncParam->load() > 0.5f;

    // Character morphing: density multiplier (1.0 to 4.0)
    float densityMultiplier = 1.0f + (characterAmount * 3.0f);

    // Calculate Tukey window alpha for character control (0.1 to 1.0)
    float tukeyAlpha = 0.1f + (characterAmount * 0.9f);

    // Tempo sync - quantize delay_time to note divisions
    float delayTimeSecQuantized = getQuantizedDelayTime(delayTimeSec, tempoSyncEnabled);

    // Handle freeze state with input gain ramp
    if (freezeRequested != freezeEnabled.load(std::memory_order_relaxed))
    {
        freezeEnabled.store(freezeRequested, std::memory_order_relaxed);

        if (!freezeRequested)
        {
            // Unfreeze: start input gain ramp from 0.0 to 1.0 over 50ms
            inputGainRamp = 0.0f;
            samplesSinceUnfreeze = 0;
        }
    }

    // Process input gain ramp for smooth unfreeze transition
    if (!freezeEnabled.load() && inputGainRamp < 1.0f)
    {
        samplesSinceUnfreeze += numSamples;
        inputGainRamp = static_cast<float>(samplesSinceUnfreeze) / static_cast<float>(unfreezeRampSamples);
        if (inputGainRamp > 1.0f)
            inputGainRamp = 1.0f;
    }
    else if (freezeEnabled.load())
    {
        inputGainRamp = 0.0f;  // No input gain when frozen
    }
    else
    {
        inputGainRamp = 1.0f;  // Normal operation
    }

    // Recalculate spawn interval with tempo-synced delay time
    float baseIntervalSamples = delayTimeSecQuantized * static_cast<float>(currentSampleRate);
    nextGrainInterval = static_cast<int>(baseIntervalSamples / densityMultiplier);
    if (nextGrainInterval < 1)
        nextGrainInterval = 1;

    // Get stereo input pointers
    const float* inputL = buffer.getReadPointer(0);
    const float* inputR = buffer.getNumChannels() > 1 ? buffer.getReadPointer(1) : buffer.getReadPointer(0);

    // Clear wet buffer
    wetBuffer.clear();

    // Store dry signal for later mixing
    for (int i = 0; i < numSamples; ++i)
    {
        dryBuffer.setSample(0, i, inputL[i]);
        dryBuffer.setSample(1, i, inputR[i]);
    }

    // Process sample by sample
    for (int sample = 0; sample < numSamples; ++sample)
    {
        // Apply input gain ramp to input only
        float inputOnlyL = inputL[sample] * inputGainRamp;
        float inputOnlyR = inputR[sample] * inputGainRamp;

        // Mix input with feedback
        float inputWithFeedbackL = inputOnlyL + feedbackSampleL;
        float inputWithFeedbackR = inputOnlyR + feedbackSampleR;

        // Write to grain buffer only if NOT frozen
        if (!freezeEnabled.load(std::memory_order_relaxed))
        {
            grainBuffer.pushSample(0, inputWithFeedbackL);
            grainBuffer.pushSample(1, inputWithFeedbackR);
        }

        // Calculate grain interval with chaos timing jitter
        int currentInterval = nextGrainInterval;
        if (chaosAmount > 0.001f)
        {
            float timingJitter = (random.nextFloat() - 0.5f) * chaosAmount;
            currentInterval = static_cast<int>(nextGrainInterval * (1.0f + timingJitter));
            currentInterval = std::max(1, currentInterval);
        }

        // Check if we should spawn a new grain
        samplesSinceLastGrain++;
        if (samplesSinceLastGrain >= currentInterval)
        {
            spawnGrain();
            samplesSinceLastGrain = 0;
        }

        // Process all active grain voices
        float leftOutput = 0.0f;
        float rightOutput = 0.0f;

        for (auto& voice : grainVoices)
        {
            if (!voice.active)
                continue;

            // Apply buffer position offset
            float bufferOffsetSamples = bufferPosition * static_cast<float>(grainBuffer.getMaximumDelayInSamples());
            float adjustedReadPos = voice.readPosition + bufferOffsetSamples;

            // Read from delay buffer with interpolation
            float delaySamples = std::max(0.0f, adjustedReadPos);
            float grainSampleL = grainBuffer.popSample(0, delaySamples, false);
            float grainSampleR = grainBuffer.popSample(1, delaySamples, false);

            // Generate ADSR envelope
            float adsrEnvelope = getADSREnvelope(voice.windowPosition, envelopeShape);
            float tukeyWindow = getWindowSample(voice.windowPosition, tukeyAlpha);
            float combinedEnvelope = adsrEnvelope * tukeyWindow;

            // Apply envelope to grain samples
            float processedL = grainSampleL * combinedEnvelope;
            float processedR = grainSampleR * combinedEnvelope;

            // Apply equal-power pan
            float leftGain = std::cos(voice.pan * juce::MathConstants<float>::halfPi);
            float rightGain = std::sin(voice.pan * juce::MathConstants<float>::halfPi);

            leftOutput += (processedL * leftGain + processedR * (1.0f - rightGain)) * 0.707f;
            rightOutput += (processedR * rightGain + processedL * (1.0f - leftGain)) * 0.707f;

            // Advance grain playback with pitch randomization
            float pitchMod = 1.0f;
            if (pitchRange > 0.001f)
            {
                float semitones = (random.nextFloat() - 0.5f) * 2.0f * pitchRange * 24.0f;
                pitchMod = std::pow(2.0f, semitones / 12.0f);
            }
            voice.readPosition -= voice.playbackRate * pitchMod;

            // Advance window position
            float windowIncrement = 1.0f / static_cast<float>(voice.grainLengthSamples);
            voice.windowPosition += windowIncrement;

            // Check if grain has finished
            if (voice.windowPosition >= 1.0f || voice.readPosition < 0.0f)
            {
                voice.active = false;
            }
        }

        // Apply distortion
        float distortedL = leftOutput;
        float distortedR = rightOutput;
        if (distortionAmount > 0.001f)
        {
            distortedL = applyDistortion(leftOutput, distortionAmount);
            distortedR = applyDistortion(rightOutput, distortionAmount);
        }

        // Apply feedback saturation
        if (feedbackSaturation > 0.001f)
        {
            float amount = feedbackSaturation / 100.0f;
            float drive = 1.0f + amount * 20.0f;
            float absDrivenL = std::abs(distortedL * drive);
            float absDrivenR = std::abs(distortedR * drive);
            float satL = std::tanh(absDrivenL);
            float satR = std::tanh(absDrivenR);
            distortedL = (distortedL > 0.0f) ? satL : -satL;
            distortedR = (distortedR > 0.0f) ? satR : -satR;
        }

        // Apply feedback gain
        feedbackSampleL = distortedL * feedbackGain;
        feedbackSampleR = distortedR * feedbackGain;

        // Write to wet buffer
        wetBuffer.setSample(0, sample, distortedL);
        wetBuffer.setSample(1, sample, distortedR);
    }

    // Linear dry/wet mix
    float wetGain = mixValue;
    float dryGain = 1.0f - wetGain;

    for (int i = 0; i < numSamples; ++i)
    {
        float dryL = dryBuffer.getSample(0, i);
        float dryR = dryBuffer.getSample(1, i);
        float wetL = wetBuffer.getSample(0, i);
        float wetR = wetBuffer.getSample(1, i);

        buffer.setSample(0, i, dryL * dryGain + wetL * wetGain);
        buffer.setSample(1, i, dryR * dryGain + wetR * wetGain);
    }
}

//==============================================================================
juce::AudioProcessorEditor* GrainCosmosAudioProcessor::createEditor()
{
    return new GrainCosmosAudioProcessorEditor(*this);
}

//==============================================================================
void GrainCosmosAudioProcessor::getStateInformation(juce::MemoryBlock& destData)
{
    auto state = parameters.copyState();
    std::unique_ptr<juce::XmlElement> xml(state.createXml());
    copyXmlToBinary(*xml, destData);
}

void GrainCosmosAudioProcessor::setStateInformation(const void* data, int sizeInBytes)
{
    std::unique_ptr<juce::XmlElement> xmlState(getXmlFromBinary(data, sizeInBytes));

    if (xmlState != nullptr && xmlState->hasTagName(parameters.state.getType()))
        parameters.replaceState(juce::ValueTree::fromXml(*xmlState));
}

//==============================================================================
// Helper function implementations
void GrainCosmosAudioProcessor::spawnGrain()
{
    int voiceIndex = findFreeVoice();
    if (voiceIndex < 0)
        return;  // No free voices

    auto& voice = grainVoices[static_cast<size_t>(voiceIndex)];
    voice.active = true;
    voice.readPosition = static_cast<float>(writePosition);
    voice.windowPosition = 0.0f;
    voice.pan = random.nextFloat();

    // Grain size from parameter
    voice.grainLengthSamples = static_cast<int>((grainSizeMs / 1000.0f) * currentSampleRate);
    if (voice.grainLengthSamples < 1)
        voice.grainLengthSamples = 1;

    // Playback rate
    voice.playbackRate = 1.0f;
}

float GrainCosmosAudioProcessor::getWindowSample(float normalizedPosition, float tukeyAlpha)
{
    // Tukey window: flat middle with tapered edges
    if (normalizedPosition <= 0.0f)
        return 0.0f;
    if (normalizedPosition >= 1.0f)
        return 0.0f;

    float halfAlpha = tukeyAlpha / 2.0f;

    if (normalizedPosition < halfAlpha)
    {
        // Rising cosine edge (left)
        return 0.5f * (1.0f - std::cos(juce::MathConstants<float>::twoPi * normalizedPosition / tukeyAlpha));
    }
    else if (normalizedPosition > 1.0f - halfAlpha)
    {
        // Falling cosine edge (right)
        float pos = 1.0f - normalizedPosition;
        return 0.5f * (1.0f - std::cos(juce::MathConstants<float>::twoPi * pos / tukeyAlpha));
    }
    else
    {
        // Flat middle section
        return 1.0f;
    }
}

float GrainCosmosAudioProcessor::getADSREnvelope(float windowPos, float envelopeShape)
{
    // envelopeShape: 0.0 = attack, 0.5 = A=D, 1.0 = decay
    if (envelopeShape <= 0.0f)
    {
        // Attack only (linear ramp up)
        return windowPos;
    }
    else if (envelopeShape >= 1.0f)
    {
        // Decay only (linear ramp down)
        return 1.0f - windowPos;
    }
    else
    {
        // Attack-Decay blend
        float attackWeight = (1.0f - envelopeShape) * 2.0f;
        if (windowPos < envelopeShape)
        {
            // Attack phase
            return windowPos / envelopeShape;
        }
        else
        {
            // Decay phase
            return 1.0f - ((windowPos - envelopeShape) / (1.0f - envelopeShape));
        }
    }
}

float GrainCosmosAudioProcessor::applyDistortion(float sample, float distortionAmount)
{
    // Simple soft saturation distortion
    float amount = distortionAmount / 100.0f;
    float drive = 1.0f + amount * 10.0f;
    float driven = sample * drive;
    return std::tanh(driven);
}

float GrainCosmosAudioProcessor::getQuantizedDelayTime(float delayTimeSec, bool tempoSync)
{
    if (!tempoSync)
        return delayTimeSec;

    // Get BPM from host
    float bpm = 120.0f;
    if (auto* playhead = getPlayHead())
    {
        if (auto position = playhead->getPosition())
        {
            if (auto bpmValue = position->getBpm())
            {
                if (bpmValue.hasValue())
                    bpm = static_cast<float>(*bpmValue);
            }
        }
    }

    // Quantize to nearest note division
    float beatDuration = 60.0f / bpm;

    // Map delay time to note divisions (1/16 to 1 beat)
    float divisions[] = {0.0625f, 0.125f, 0.25f, 0.5f, 1.0f}; // 1/16, 1/8, 1/4, 1/2, 1
    int numDivisions = 5;
    int bestIndex = 0;
    float bestDiff = std::abs(delayTimeSec - divisions[0] * beatDuration);

    for (int i = 1; i < numDivisions; ++i)
    {
        float quantizedTime = divisions[i] * beatDuration;
        float diff = std::abs(delayTimeSec - quantizedTime);
        if (diff < bestDiff)
        {
            bestDiff = diff;
            bestIndex = i;
        }
    }

    return divisions[bestIndex] * beatDuration;
}

int GrainCosmosAudioProcessor::findFreeVoice()
{
    for (int i = 0; i < maxGrainVoices; ++i)
    {
        if (!grainVoices[static_cast<size_t>(i)].active)
            return i;
    }
    return -1;  // No free voices
}

juce::AudioProcessorValueTreeState::ParameterLayout GrainCosmosAudioProcessor::createParameterLayout()
{
    juce::AudioProcessorValueTreeState::ParameterLayout layout;

    // 14 parameters for v1.0
    layout.add(std::make_unique<juce::AudioParameterFloat>(
        "delay_time",
        "Delay Time",
        juce::NormalisableRange<float>(0.01f, 2.0f, 0.01f),
        0.1f,
        "s"));

    layout.add(std::make_unique<juce::AudioParameterFloat>(
        "mix",
        "Mix",
        juce::NormalisableRange<float>(0.0f, 100.0f, 1.0f),
        30.0f,
        "%"));

    layout.add(std::make_unique<juce::AudioParameterFloat>(
        "feedback",
        "Feedback",
        juce::NormalisableRange<float>(0.0f, 95.0f, 1.0f),
        40.0f,
        "%"));

    layout.add(std::make_unique<juce::AudioParameterFloat>(
        "feedback_saturation",
        "Feedback Saturation",
        juce::NormalisableRange<float>(0.0f, 100.0f, 1.0f),
        0.0f,
        "%"));

    layout.add(std::make_unique<juce::AudioParameterFloat>(
        "grain_density",
        "Grain Density",
        juce::NormalisableRange<float>(1.0f, 32.0f, 1.0f),
        8.0f,
        ""));

    layout.add(std::make_unique<juce::AudioParameterFloat>(
        "pitch_range",
        "Pitch Range",
        juce::NormalisableRange<float>(0.0f, 100.0f, 1.0f),
        0.0f,
        "%"));

    layout.add(std::make_unique<juce::AudioParameterFloat>(
        "buffer_position",
        "Buffer Position",
        juce::NormalisableRange<float>(0.0f, 100.0f, 1.0f),
        100.0f,
        "%"));

    layout.add(std::make_unique<juce::AudioParameterFloat>(
        "character",
        "Character",
        juce::NormalisableRange<float>(0.0f, 100.0f, 1.0f),
        50.0f,
        "%"));

    layout.add(std::make_unique<juce::AudioParameterFloat>(
        "chaos",
        "Chaos",
        juce::NormalisableRange<float>(0.0f, 100.0f, 1.0f),
        0.0f,
        "%"));

    layout.add(std::make_unique<juce::AudioParameterFloat>(
        "grain_size",
        "Grain Size",
        juce::NormalisableRange<float>(10.0f, 200.0f, 1.0f),
        100.0f,
        "ms"));

    layout.add(std::make_unique<juce::AudioParameterFloat>(
        "envelope_shape",
        "Envelope Shape",
        juce::NormalisableRange<float>(0.0f, 1.0f, 0.01f),
        0.5f,
        ""));

    layout.add(std::make_unique<juce::AudioParameterFloat>(
        "distortion_amount",
        "Distortion Amount",
        juce::NormalisableRange<float>(0.0f, 100.0f, 1.0f),
        0.0f,
        "%"));

    layout.add(std::make_unique<juce::AudioParameterBool>(
        "freeze",
        "Freeze",
        false,
        ""));

    layout.add(std::make_unique<juce::AudioParameterBool>(
        "tempo_sync",
        "Tempo Sync",
        false,
        ""));

    return layout;
}

// This creates new instances of the plugin..
juce::AudioProcessor* JUCE_CALLTYPE createPluginFilter()
{
    return new GrainCosmosAudioProcessor();
}
